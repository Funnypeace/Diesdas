// /api/groq.js — Vercel API Route: Firecrawl → Groq News-Summary
// Drop-in: ersetzt deine bestehende Datei vollständig.

export default async function handler(req, res) {
  // ---------- CORS ----------
  res.setHeader("Access-Control-Allow-Origin", "*");
  res.setHeader("Access-Control-Allow-Methods", "POST, OPTIONS");
  res.setHeader("Access-Control-Allow-Headers", "Content-Type");
  if (req.method === "OPTIONS") return res.status(200).end();

  if (req.method !== "POST") {
    return res.status(405).json({ error: "Method not allowed" });
  }

  // ---------- Parse Body ----------
  let body = req.body;
  if (typeof body === "string") {
    try { body = JSON.parse(body); } catch { body = {}; }
  }

  // Support altes Schema (messages/action) & neues Schema (query/targets/sites)
  const payload = normalizePayload(body);

  // ---------- Validate ----------
  if (!payload.targets.length && !payload.query) {
    return res.status(400).json({
      error: "Bitte mindestens eine Ziel-URL (targets[]) oder eine Query übergeben.",
      received: payload
    });
  }

  // ---------- Keys ----------
  const GROQ_API_KEY = process.env.GROQ_API_KEY || "";
  if (!GROQ_API_KEY || !GROQ_API_KEY.startsWith("gsk_")) {
    return res.status(500).json({
      error: "GROQ_API_KEY fehlt oder hat ein falsches Format (muss mit gsk_ beginnen)."
    });
  }
  const FIRECRAWL_API_KEY = process.env.FIRECRAWL_API_KEY || "";

  const debug = {
    firecrawlUsed: !!FIRECRAWL_API_KEY,
    query: payload.query || null,
    targets: payload.targets,
    scrapedCount: 0,
    scrapeErrors: [],
    groqTokens: null
  };

  try {
    // ---------- SCRAPE ----------
    const scraped = [];
    for (const url of payload.targets) {
      try {
        const text = FIRECRAWL_API_KEY
          ? await scrapeWithFirecrawl(url, FIRECRAWL_API_KEY)
          : await scrapeWithFallbackFetch(url);
        if (text) scraped.push({ url, text });
      } catch (e) {
        debug.scrapeErrors.push({ url, error: String(e.message || e) });
      }
    }
    debug.scrapedCount = scraped.length;

    // Falls Query vorhanden aber keine Targets: (optionale) Firecrawl-Suche
    if (scraped.length === 0 && payload.query && FIRECRAWL_API_KEY && payload.sites.length) {
      const candidates = await firecrawlSiteSearch(payload.query, payload.sites, FIRECRAWL_API_KEY);
      for (const c of candidates.slice(0, 5)) { // max. 5 Treffer scrapen
        try {
          const text = await scrapeWithFirecrawl(c, FIRECRAWL_API_KEY);
          if (text) scraped.push({ url: c, text });
        } catch (e) {
          debug.scrapeErrors.push({ url: c, error: String(e.message || e) });
        }
      }
      debug.scrapedCount = scraped.length;
    }

    if (scraped.length === 0) {
      return res.status(200).json({
        content: "Keine relevanten Nachrichten gefunden. Es liegen keine Eingangsdaten vor, um eine Zusammenfassung zu erstellen.",
        model: "llama-3.3-70b-versatile",
        action: "news_summary",
        timestamp: new Date().toISOString(),
        debug
      });
    }

    // ---------- PREPARE PROMPT ----------
    const MAX_PER_SOURCE = 2500;  // Zeichen pro Quelle
    const MAX_TOTAL = 11000;      // Zeichen gesamt fürs LLM
    let total = 0;

    const sourceBlocks = scraped.map(({ url, text }) => {
      const clean = collapseWhitespace(text).slice(0, MAX_PER_SOURCE);
      total += clean.length;
      return `Quelle: ${url}\n---\n${clean}`;
    }).filter(Boolean);

    // hart kappen
    let material = "";
    for (const block of sourceBlocks) {
      if (material.length + block.length > MAX_TOTAL) break;
      material += block + "\n\n";
    }

    const systemPrompt = `
Du bist ein präziser deutschsprachiger News-Summarizer.
Fasse die gelieferten Artikel in **maximal 3 Sätzen** zusammen.
- Neutral, faktenbasiert, keine Spekulation.
- Wenn mehrere Quellen, fasse sie zu einer Gesamtmeldung zusammen.
- Nenne keine Anweisungen oder Metakommentare.
`.trim();

    const userPrompt = `
Thema/Keywords: ${payload.query || "—"}
Material (Auszüge):
${material}
`.trim();

    // ---------- CALL GROQ ----------
    const groqResp = await fetch("https://api.groq.com/openai/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${GROQ_API_KEY}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        model: "llama-3.3-70b-versatile",
        temperature: 0.3,
        max_tokens: 400,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: userPrompt }
        ]
      })
    });

    if (!groqResp.ok) {
      const txt = await groqResp.text().catch(() => "");
      throw new Error(`Groq HTTP ${groqResp.status} – ${groqResp.statusText} – ${txt}`);
    }

    const groqJson = await groqResp.json();
    const summary =
      groqJson?.choices?.[0]?.message?.content?.trim?.() ||
      groqJson?.content || "";

    debug.groqTokens = groqJson?.usage || null;

    return res.status(200).json({
      summary: summary || "Keine Zusammenfassung erzeugt.",
      model: "llama-3.3-70b-versatile",
      action: "news_summary",
      timestamp: new Date().toISOString(),
      debug
    });

  } catch (err) {
    return res.status(500).json({
      error: "Unerwarteter Fehler in /api/groq",
      detail: String(err?.message || err),
      timestamp: new Date().toISOString(),
      debug
    });
  }
}

// ------------------------ Utils ------------------------

function normalizePayload(body) {
  // Neues Schema
  const out = {
    query: body?.query ?? null,
    targets: Array.isArray(body?.targets) ? body.targets.filter(Boolean) : [],
    sites: Array.isArray(body?.sites) ? dedupe(body.sites) : []
  };

  // Fallback: altes Schema (messages/action)
  if ((!out.targets.length && !out.query) && Array.isArray(body?.messages)) {
    const last = body.messages[body.messages.length - 1];
    const text = typeof last?.content === "string" ? last.content : "";
    const urls = extractUrls(text);
    out.targets = urls;
    // action ignorieren – wir wollen dennoch eine Zusammenfassung fahren
  }
  return out;
}

function dedupe(arr) {
  return Array.from(new Set((arr || []).map(String))).filter(Boolean);
}

function extractUrls(text = "") {
  const m = text.match(/https?:\/\/[^\s)]+/g) || [];
  return dedupe(m);
}

function collapseWhitespace(s = "") {
  return s.replace(/\u00a0/g, " ").replace(/\s+/g, " ").trim();
}

// --- Firecrawl Search (site: Filter) ---
async function firecrawlSiteSearch(query, sites, key) {
  try {
    const q = `${query} ${sites.map((s) => `site:${s}`).join(" ")}`.trim();
    const resp = await fetch("https://api.firecrawl.dev/v1/search", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${key}`,
        "Content-Type": "application/json"
      },
      body: JSON.stringify({ query: q, limit: 5 })
    });
    if (!resp.ok) return [];
    const js = await resp.json();
    // API-Formate variieren: urls / data / results
    const urls =
      js?.urls ||
      js?.data?.map?.(x => x?.url).filter(Boolean) ||
      js?.results?.map?.(x => x?.url).filter(Boolean) ||
      [];
    return urls.slice(0, 5);
  } catch {
    return [];
  }
}

// --- Firecrawl Scrape ---
async function scrapeWithFirecrawl(url, key) {
  const resp = await fetch("https://api.firecrawl.dev/v1/scrape", {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${key}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      url,
      formats: ["markdown", "html", "links"],
      include_images: false,
      mobile: false
    })
  });

  if (!resp.ok) {
    const t = await resp.text().catch(() => "");
    throw new Error(`Firecrawl HTTP ${resp.status} – ${t.slice(0, 200)}`);
  }

  const js = await resp.json();
  // unterschiedliche Shapes unterstützen
  const md = js?.markdown || js?.data?.markdown || "";
  const txt = js?.text || js?.data?.text || "";
  const html = js?.html || js?.data?.html || "";
  const best = md || txt || extractTextFromHtml(html);
  return best || "";
}

// --- Fallback: Direkt-Fetch + einfache Extraktion ---
async function scrapeWithFallbackFetch(url) {
  const resp = await fetch(url, {
    headers: {
      "User-Agent": "Mozilla/5.0 (compatible; NewsSummarizerBot/1.0; +https://example.invalid)",
      "Accept": "text/html,application/xhtml+xml"
    }
  });
  if (!resp.ok) throw new Error(`Fetch HTTP ${resp.status}`);
  const html = await resp.text();
  return extractTextFromHtml(html);
}

// sehr einfache HTML→Text Extraktion (ohne Abhängigkeiten)
function extractTextFromHtml(html = "") {
  const noScripts = html
    .replace(/<script[\s\S]*?<\/script>/gi, " ")
    .replace(/<style[\s\S]*?<\/style>/gi, " ");
  const keep = [];
  const h1 = (noScripts.match(/<h1[^>]*>[\s\S]*?<\/h1>/gi) || []).join(" ");
  const paras = (noScripts.match(/<(p|h2|li)[^>]*>[\s\S]*?<\/(p|h2|li)>/gi) || []).join(" ");
  keep.push(h1, paras);
  const text = keep.join(" ").replace(/<[^>]+>/g, " ");
  return collapseWhitespace(text);
}
